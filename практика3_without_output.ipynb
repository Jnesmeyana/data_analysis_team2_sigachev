{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86eb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import Linear, Sigmoid, ReLU\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr=[]\n",
    "Y_arr=[]\n",
    "#это пример с рандомными значениями\n",
    "# Предположим нам надо предсказывать плотность загрузки по средним размерам коробки в контейнере\n",
    "folder_path = \"C:/Users/AliSa/Prakticum/ALGORITM\"\n",
    "directory_contents = os.listdir(folder_path)\n",
    "for filename in directory_contents:\n",
    "    df = pd.pandas.read_json(\"C://Users//AliSa//Prakticum//ALGORITM//\"+filename)\n",
    "    data = pd.DataFrame(df['data'])['data']\n",
    "    cargoes = pd.DataFrame(list(data[0]))\n",
    "    sizes = pd.DataFrame(list(cargoes['size']))\n",
    "    sizes = sizes.iloc[:].values\n",
    "    avg_width=0\n",
    "    avg_height=0\n",
    "    avg_length=0\n",
    "    i=0\n",
    "    for size in sizes:\n",
    "        avg_width += size[0]\n",
    "        avg_height += size[1]\n",
    "        avg_length += size[2]\n",
    "        i+=1\n",
    "    avg_width /= i\n",
    "    avg_height /= i\n",
    "    avg_length /= i\n",
    "    avg_all = (avg_width+avg_height+avg_length)/i\n",
    "    avg_all = 1/avg_all\n",
    "    X_arr.append([avg_width,avg_height,avg_length])\n",
    "    data_result = pd.DataFrame(df['data_result'])['data_result']\n",
    "    cargo_space = data_result['cargo_space']\n",
    "    calculation_info = cargo_space['calculation_info']['density_percent']\n",
    "    Y_arr.append(calculation_info)\n",
    "X_arr= np.vstack(X_arr)\n",
    "X_arr\n",
    "print(Y_arr)\n",
    "print(X_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02787799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В библиотеке torch для обучения данные должны быть в формате тензоров\n",
    "# соответственно разделяем\n",
    "# затем приводим к формату\n",
    "X = torch.autograd.Variable(torch.FloatTensor(X_arr))\n",
    "Y = torch.autograd.Variable(torch.FloatTensor(Y_arr))\n",
    "# количество признаков потом указывает на вход в нейроне\n",
    "num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сеть то есть Sequential - последовательность\n",
    "# сюда внутрь можно добавлять разные слои\n",
    "# документация - https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "model = torch.nn.Sequential(\n",
    "    Linear(num_features, 1),\n",
    "    ReLU()\n",
    ")\n",
    "\n",
    "# Пока здесь один слой линейный - Linear\n",
    "# ReLU() - функция активация, после слоя\n",
    "# функция активация тоже могут быть разные - можно погулить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ccd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем какую-нибудь функцию потерь для обучения\n",
    "# здесь стандартная как для регрессии - квадратичная ошибка\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# шаг градиентного спуска (точнее -- метода оптимизации)\n",
    "learning_rate = 0.00001  \n",
    "# сам метод оптимизации нейросети (обычно лучше всего по-умолчанию работает Adam)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "# итерируемся num_epochs раз, здесь 100000\n",
    "for t in range(50000):\n",
    "    # foward_pass() -- применение нейросети\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # выведем loss - смотрим - ошибка на каждом этапе уменьшается\n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    print('{} {}'.format(t, loss.data))\n",
    "\n",
    "    # обнуляем градиенты перед backard_pass'ом (обязательно!)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward_pass() -- вычисляем градиенты loss'а по параметрам (весам) нейросети\n",
    "    # этой командой мы только вычисляем градиенты, но ещё не обновляем веса\n",
    "    loss.backward()\n",
    "\n",
    "    # а тут уже обновляем веса\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d09af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь можно посмотреть как можель прогнозирует\n",
    "# Допустим есть вот такие параметры коробок - 1520, 1200, 1414\n",
    "x = [[137.02475248, 180.57920792, 228.21287129]]\n",
    "# также приводим к тензору\n",
    "x = torch.autograd.Variable(torch.FloatTensor(x))\n",
    "# смотрим какую плотность модель предсказала\n",
    "c = model(x)\n",
    "c\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6c089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e72942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
